{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Junnan Shimizu**\n",
    "\n",
    "Spring 2022\n",
    "\n",
    "CS 251: Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6B: Naive Bayes and K-Nearest Neighbor\n",
    "\n",
    "In this lab we will be using the library scikit-learn to train a Gaussian Naive Bayes classifier and graph the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/0p9b6l2s6x13bk377kvjypbm0000gn/T/ipykernel_93667/733670150.py:8: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
      "/var/folders/b_/0p9b6l2s6x13bk377kvjypbm0000gn/T/ipykernel_93667/733670150.py:8: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing, model_selection, decomposition\n",
    "from sklearn import neighbors, naive_bayes, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load the digits dataset\n",
    "\n",
    "We're going to be seeing if we can use Naive Bayes and K-Nearest Neighbor to classify hand writing data.  The [digits dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html) is a set of 1797 8x8 pixel images, representing handwriting samples of the numbers 0-9.  This is just a small sample of the [MNIST handwriting dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "1. Load the [digits dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). Use the `return_X_y` parameter so that it returns both the X data and y classifications.\n",
    "2. Use [train test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split the X data and y classifications, into an X_training dataset, X_testing dataset and the corresponding y_training labels and y_testing labels.  Set the test size be .3 and shuffle to True.\n",
    "4. Print the shape of X_training, X_testing, y_training, and y_testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_training shape: (1257, 64)\n",
      "X_testing shape: (540, 64)\n",
      "y_training shape: (1257,)\n",
      "y_testing shape: (540,)\n",
      "Expected output\n",
      "\n",
      "X training data shape:  (1257, 64)\n",
      "X testing data shape:   (540, 64)\n",
      "y training labels shape:(1257,)\n",
      "y testing labels shape: (540,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Your code here\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "\n",
    "X_training, X_testing, y_training, y_testing = model_selection.train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "print(\"X_training shape:\", X_training.shape)\n",
    "print(\"X_testing shape:\", X_testing.shape)\n",
    "print(\"y_training shape:\", y_training.shape)\n",
    "print(\"y_testing shape:\", y_testing.shape)\n",
    "\n",
    "print( \"Expected output\")\n",
    "print('''\n",
    "X training data shape:  (1257, 64)\n",
    "X testing data shape:   (540, 64)\n",
    "y training labels shape:(1257,)\n",
    "y testing labels shape: (540,)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create Classifiers and Calculate Accuracy\n",
    "\n",
    "### Create a Naive Bayes Classifier\n",
    "1. Create a [Gaussian Naive Bayes Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) [(More Info)](https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes). \n",
    "2. Use the fit method with the training dataset as X and the y training dataset labels as the target.\n",
    "3. Calculate the accuracy of the classifier with the test data and test dataset labels using the score method.\n",
    "4. Print the accuracy of the Naive Bayes classifier.\n",
    "\n",
    "### Create a K-NN Classifier\n",
    "1. Using the lab from last week as reference, create a [K-Nearest Neighbors Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) [(More Info)](https://scikit-learn.org/stable/modules/neighbors.html#classification).  Set n_neighbors equal to 7.\n",
    "1. Assign your classifier to a variable with a **different** name than your Naive Bayes classifier.  \n",
    "2. Use the fit method with the training dataset as X and the y training dataset labels as the target.\n",
    "3. Calculate the accuracy of the classifier with the test data and test dataset labels using the score method.\n",
    "4. Print the accuracy of the K-NN classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.8518518518518519\n",
      "KNN Accuracy: 0.9907407407407407\n",
      "Expected output\n",
      "\n",
      "Gaussian Naive Bayes Classifier Accuracy: 0.85185...\n",
      "K-Nearest Neighbor Classifier Accuracy:   0.99074...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "gnb.fit(X_training, y_training)\n",
    "gnb_accuracy = gnb.score(X_testing, y_testing)\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "knn.fit(X_training, y_training)\n",
    "knn_accuracy = knn.score(X_testing, y_testing)\n",
    "\n",
    "print(\"GNB Accuracy:\", gnb_accuracy)\n",
    "\n",
    "print(\"KNN Accuracy:\", knn_accuracy)\n",
    "\n",
    "print( \"Expected output\")\n",
    "print('''\n",
    "Gaussian Naive Bayes Classifier Accuracy: 0.85185...\n",
    "K-Nearest Neighbor Classifier Accuracy:   0.99074...\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create a confusion matrix for each classifier\n",
    "\n",
    "1. Find the predicted labels for the X test data using the predict method for the Naive Bayes classifier and K-NN classifier.\n",
    "1. Create a [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) for each classifier, using the predicted labels and actual labels.  \n",
    "1. Print the confusion matrices, along with some indication that the rows indicate the number of points that truly have a given label and that the columns indicate the number of points predicted to have that label.\n",
    "2. Visualize the confusion matrices using imshow. For reference, use Lab 4a and this [matplotlib example](https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html) of an annotated heatmap.\n",
    "    1. Set x_ticks and y_ticks to align with the list of digits.\n",
    "    2. Use imshow to draw the matrix\n",
    "    3. Choose a perceptually uniform [colormap](https://matplotlib.org/tutorials/colors/colormaps.html)\n",
    "    3. Use a colorbar to label the matrix\n",
    "    4. Remember to call `plt.show()` at the end, or other plots later might not work.\n",
    "    5. Give your plot a meaningful title.\n",
    "    \n",
    "#### Review Question: Which digits are most likely to be misclassified and what are they most likely to be misclassified as?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Naive Bayes Classifier):\n",
      " [[176   0   0   0   1   0   0   1   0   0]\n",
      " [  0 144   2   0   0   0   5   5  17   9]\n",
      " [  0  14 113   0   0   1   1   0  48   0]\n",
      " [  0   2   3 144   0   3   1   6  19   5]\n",
      " [  1   1   0   0 152   1   4  19   3   0]\n",
      " [  0   0   0   2   0 169   1   7   2   1]\n",
      " [  0   0   0   0   1   1 178   0   1   0]\n",
      " [  0   0   0   0   1   1   0 177   0   0]\n",
      " [  0   7   0   1   0   3   0  12 151   0]\n",
      " [  1   3   1   2   0   4   1  17  12 139]]\n",
      "Rows indicate the true labels, columns indicate predicted labels.\n",
      "\n",
      "Confusion Matrix (K-NN Classifier):\n",
      " [[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0 176   0   0   0   0   1   0   0]\n",
      " [  0   0   0 181   0   0   0   1   1   0]\n",
      " [  0   0   0   0 180   0   0   1   0   0]\n",
      " [  0   0   0   0   0 178   1   0   0   3]\n",
      " [  0   0   0   0   0   0 181   0   0   0]\n",
      " [  0   0   0   0   0   0   0 179   0   0]\n",
      " [  0   3   0   2   0   0   0   0 169   0]\n",
      " [  0   0   0   2   1   2   0   0   1 174]]\n",
      "Rows indicate the true labels, columns indicate predicted labels.\n",
      "Confusion Matrix (Naive Bayes Classifier):\n",
      " [[176   0   0   0   1   0   0   1   0   0]\n",
      " [  0 144   2   0   0   0   5   5  17   9]\n",
      " [  0  14 113   0   0   1   1   0  48   0]\n",
      " [  0   2   3 144   0   3   1   6  19   5]\n",
      " [  1   1   0   0 152   1   4  19   3   0]\n",
      " [  0   0   0   2   0 169   1   7   2   1]\n",
      " [  0   0   0   0   1   1 178   0   1   0]\n",
      " [  0   0   0   0   1   1   0 177   0   0]\n",
      " [  0   7   0   1   0   3   0  12 151   0]\n",
      " [  1   3   1   2   0   4   1  17  12 139]]\n",
      "Rows indicate the true labels, columns indicate predicted labels.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'knn_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRows indicate the true labels, columns indicate predicted labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# K-NN classifier\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m knn_pred \u001b[38;5;241m=\u001b[39m \u001b[43mknn_classifier\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     20\u001b[0m knn_cm \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(y, knn_pred)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConfusion Matrix (K-NN Classifier):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, knn_cm)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code goes here\n",
    "# Naive Bayes classifier\n",
    "nb_pred = gnb.predict(X)\n",
    "nb_cm = metrics.confusion_matrix(y, nb_pred)\n",
    "print(\"Confusion Matrix (Naive Bayes Classifier):\\n\", nb_cm)\n",
    "print(\"Rows indicate the true labels, columns indicate predicted labels.\")\n",
    "\n",
    "# K-NN classifier\n",
    "knn_pred = knn.predict(X)\n",
    "knn_cm = metrics.confusion_matrix(y, knn_pred)\n",
    "print(\"\\nConfusion Matrix (K-NN Classifier):\\n\", knn_cm)\n",
    "print(\"Rows indicate the true labels, columns indicate predicted labels.\")# Naive Bayes classifier\n",
    "nb_pred = gnb.predict(X)\n",
    "nb_cm = metrics.confusion_matrix(y, nb_pred)\n",
    "print(\"Confusion Matrix (Naive Bayes Classifier):\\n\", nb_cm)\n",
    "print(\"Rows indicate the true labels, columns indicate predicted labels.\")\n",
    "\n",
    "# K-NN classifier\n",
    "knn_pred = knn_classifier.predict(X)\n",
    "knn_cm = metrics.confusion_matrix(y, knn_pred)\n",
    "print(\"\\nConfusion Matrix (K-NN Classifier):\\n\", knn_cm)\n",
    "print(\"Rows indicate the true labels, columns indicate predicted labels.\")\n",
    "\n",
    "print(\"Expected output (rows indicate true class count, columns indicate predicted class count)\")\n",
    "print('''\n",
    "K-Nearest Neighbor Confusion Matrix\n",
    " [[53  0  0  0  0  0  0  0  0  0]\n",
    " [ 0 50  0  0  0  0  0  0  0  0]\n",
    " [ 0  0 47  0  0  0  0  0  0  0]\n",
    " [ 0  0  0 54  0  0  0  0  0  0]\n",
    " [ 0  0  0  0 60  0  0  0  0  0]\n",
    " [ 0  0  0  0  0 64  1  0  0  1]\n",
    " [ 0  0  0  0  0  0 53  0  0  0]\n",
    " [ 0  0  0  0  0  0  0 55  0  0]\n",
    " [ 0  0  0  0  0  0  0  0 43  0]\n",
    " [ 0  0  0  1  1  1  0  0  0 56]]\n",
    " Gaussian Naive Bayes Confusion Matrix\n",
    "[[52  0  0  0  0  0  0  1  0  0]\n",
    " [ 0 37  2  0  0  0  0  2  6  3]\n",
    " [ 0  3 31  0  0  0  1  0 12  0]\n",
    " [ 0  0  2 41  0  0  1  0  8  2]\n",
    " [ 0  0  0  0 51  0  2  7  0  0]\n",
    " [ 0  0  0  1  0 62  1  2  0  0]\n",
    " [ 0  0  0  0  1  1 51  0  0  0]\n",
    " [ 0  0  0  0  0  1  0 54  0  0]\n",
    " [ 0  2  0  0  0  0  0  2 39  0]\n",
    " [ 0  1  1  1  0  2  1  7  4 42]]\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
